{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS CODE IS AN OLD EXPERIMENT, DONT USE THIS CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "def make_dataset():\n",
    "    inv_arr = np.array([\n",
    "          [0.367322, 0.860646, -0.227968],\n",
    "          [0.280085, 0.672501, 0.047413],\n",
    "          [-0.01182, 0.04294, 0.968881]\n",
    "        ])\n",
    "    \n",
    "    path = 'test2.jpeg'\n",
    "    im = Image.open(path)\n",
    "    height, width = im.size\n",
    "    pixels = list(im.getdata())\n",
    "    pixels = np.array(pixels)\n",
    "\n",
    "    new_pixels = []\n",
    "    original_pixels = []\n",
    "    pixel = []\n",
    "    seen = set()\n",
    "    index = 0\n",
    "    for i in range(len(pixels)):\n",
    "        # print(original_pixels)\n",
    "        pixel = pixels[i][0:3]/255.0\n",
    "        pixelt = tuple(pixel)\n",
    "        if pixelt not in seen:\n",
    "            seen.add(pixelt)\n",
    "            original_pixels.append(pixel)\n",
    "            new_rgb = np.dot(inv_arr, original_pixels[index])\n",
    "            for j in range(len(new_rgb)):\n",
    "                if new_rgb[j] < 0:\n",
    "                    new_rgb[j] = 0\n",
    "                elif new_rgb[j] > 1:\n",
    "                    new_rgb[j] = 1\n",
    "            new_pixels.append(new_rgb)\n",
    "            index += 1\n",
    "    \n",
    "    return new_pixels, original_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.83442254 -2.48858426  0.72461281]\n",
      " [-0.63975098  1.43302277 -0.12779461]\n",
      " [ 0.3529891  -0.08406001  1.03311733]]\n",
      "[[ 0.04275442  0.33837656 -0.07933738]\n",
      " [ 0.10029734  0.26270859  0.16599437]\n",
      " [ 0.29285065  0.00950492  0.98691533]]\n"
     ]
    }
   ],
   "source": [
    "inv_arr = np.array([[1122508.8567174524646, -1457971.8138845102955, 335462.16373308021324],\n",
    "                    [-469939.31930043187626, 610382.67276321843644, -140441.60263851115842],\n",
    "                    [34521.524374160328152, -44838.384495688852765, 10317.804965339063583]])\n",
    "pixel = [210, 20, 8]\n",
    "\n",
    "arr = np.array([\n",
    "          [0.367322, 0.860646, -0.227968],\n",
    "          [0.280085, 0.672501, 0.047413],\n",
    "          [-0.01182, 0.04294, 0.968881]\n",
    "        ])\n",
    "inv2 = np.array([\n",
    "    [ 1.83442254, -2.48858426,  0.72461281],\n",
    "    [-0.63975098,  1.43302277, -0.12779461],\n",
    "    [ 0.3529891, -0.08406001, 1.03311733]])\n",
    "print(inv2)\n",
    "new_rgb = np.dot(arr, inv2)\n",
    "print(new_rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def make_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # 3 inputs, 3 hidden nodes, 3 outputs\n",
    "    model.add(tf.keras.layers.Dense(3, input_dim = 3, kernel_initializer='he_uniform', activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dense(64))\n",
    "    model.add(tf.keras.layers.Dense(64))\n",
    "    model.add(tf.keras.layers.Dense(3))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 3)                 12        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4623 (18.06 KB)\n",
      "Trainable params: 4623 (18.06 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotLearning(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback to plot the learning curves of the model during training.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.loss = []\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Storing metrics\n",
    "        \n",
    "        self.loss.append(logs['loss'])\n",
    "        \n",
    "        print(\"Epoch: \", epoch)\n",
    "        print(\"Loss: \", self.loss)\n",
    "        clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset_x, dataset_y):\n",
    "    results = []\n",
    "    #split into train and test\n",
    "    dataset_x = np.array(dataset_x)\n",
    "    dataset_y = np.array(dataset_y)\n",
    "    train_x = dataset_x[:int(len(dataset_x)*0.6)]\n",
    "    train_y = dataset_y[:int(len(dataset_y)*0.6)]\n",
    "    test_x = dataset_x[int(len(dataset_x)*0.6):]\n",
    "    test_y = dataset_y[int(len(dataset_y)*0.6):]\n",
    "    print(len(train_x), len(train_y), len(test_x), len(test_y))\n",
    "    print(\"Split into train and test\")\n",
    "    #train model\n",
    "    print(\"Training model\")\n",
    "    callbacks = [PlotLearning()]\n",
    "    weights = {0: 10, 1: 5, 2: 1}\n",
    "    history = model.fit(train_x, train_y, epochs=10, verbose=0, callbacks=callbacks, class_weight=weights)\n",
    "    print(\"Model trained\")\n",
    "    #evaluate model\n",
    "    print(\"Evaluating model\")\n",
    "    mae = model.evaluate(test_x, test_y, verbose=2)\n",
    "    print('MAE: %.3f' % mae)\n",
    "    results.append(mae)\n",
    "    return results, model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained\n",
      "Evaluating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 12:41:36.841193: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2720/2720 - 9s - loss: 0.0753 - 9s/epoch - 3ms/step\n",
      "MAE: 0.075\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "dataset_x, dataset_y = make_dataset()\n",
    "results, model, history = evaluate_model(model, dataset_x, dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "# plot learning curves\n",
    "plt.plot(history_dict['loss'], label='train')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[226], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m pixels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(pixels)\n\u001b[1;32m     11\u001b[0m pixels2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(pixels2)\n\u001b[0;32m---> 13\u001b[0m test_x \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39;49m(\u001b[39mlist\u001b[39;49m(original_pixels)))\n\u001b[1;32m     14\u001b[0m test_y \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(new_pixels))\n\u001b[1;32m     15\u001b[0m test_x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(test_x)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "original_pixels, new_pixels = make_dataset()\n",
    "\n",
    "path = 'test6_images/test6.jpeg_1_1.0.png'\n",
    "path2 = 'test6_images/test6.jpeg'\n",
    "im = Image.open(path)\n",
    "im2 = Image.open(path2)\n",
    "height, width = im.size\n",
    "pixels = list(im.getdata())\n",
    "pixels2 = list(im2.getdata())\n",
    "pixels = np.array(pixels)\n",
    "pixels2 = np.array(pixels2)\n",
    "\n",
    "test_x = list(set(original_pixels))\n",
    "test_y = list(set(new_pixels))\n",
    "test_x = np.array(test_x)\n",
    "print(test_x.shape)\n",
    "test_y = np.array(test_y)\n",
    "print(test_y.shape)\n",
    "# print(model.evaluate(test_x, test_y, verbose=2))\n",
    "# print(model.predict(test_x)*255)\n",
    "# print(test_y * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5t/bmhkrbcn4yzgbdrrgwk7ps_r0000gn/T/ipykernel_33568/3840544482.py:20: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if original_pixels.index(pixel) != -1:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array([0.25882353, 0.38431373, 0.48235294]) is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[271], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m original_pixels, new_pixels \u001b[39m=\u001b[39m make_dataset()\n",
      "Cell \u001b[0;32mIn[270], line 20\u001b[0m, in \u001b[0;36mmake_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(pixels)):\n\u001b[1;32m     19\u001b[0m     pixel \u001b[39m=\u001b[39m pixels[i][\u001b[39m0\u001b[39m:\u001b[39m3\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m255.0\u001b[39m\n\u001b[0;32m---> 20\u001b[0m     \u001b[39mif\u001b[39;00m original_pixels\u001b[39m.\u001b[39;49mindex(pixel) \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m     21\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: array([0.25882353, 0.38431373, 0.48235294]) is not in list"
     ]
    }
   ],
   "source": [
    "original_pixels, new_pixels = make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5t/bmhkrbcn4yzgbdrrgwk7ps_r0000gn/T/ipykernel_33568/2696741982.py:3: RuntimeWarning: invalid value encountered in cast\n",
      "  new_image = Image.fromarray(new_pixels2.reshape(533, 800, 3).astype('uint8'))\n"
     ]
    }
   ],
   "source": [
    "new_pixels2 = np.array(new_pixels2) * 255.0\n",
    "new_pixels2 = np.ravel(new_pixels2)\n",
    "new_image = Image.fromarray(new_pixels2.reshape(533, 800, 3).astype('uint8'))\n",
    "new_image.save(f'remake2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n",
      "[[0.28122568 0.30726272 0.09104604]\n",
      " [0.25590587 0.28977937 0.07912391]]\n",
      "[[0.11764706 0.37647059 0.08627451]\n",
      " [0.09803922 0.35686275 0.0745098 ]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(test_x))\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 13:18:30.265154: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71.975266 78.408806 23.022554]\n",
      "[30 96 22]\n",
      "[65.070946 73.79988  20.171082]\n",
      "[25 91 19]\n",
      "[50.419373 64.05945  14.080008]\n",
      "[15 80 16]\n",
      "[34.86462  55.34529  11.450762]\n",
      "[ 5 68 11]\n",
      "[27.30668 55.59794 20.20458]\n",
      "[ 8 65 20]\n",
      "[40.60398  73.22723  45.825428]\n",
      "[26 80 44]\n",
      "[ 65.75455  100.26859   79.525764]\n",
      "[ 55 105  80]\n",
      "[ 85.58534 122.74574 108.91968]\n",
      "[ 78 125 109]\n",
      "[ 82.828064 124.96677  116.9894  ]\n",
      "[ 83 124 116]\n",
      "[ 71.23104 117.69838 113.28788]\n",
      "[ 75 116 112]\n",
      "[48.37344 98.68174 95.11656]\n",
      "[59 94 96]\n",
      "[24.679539 77.45088  72.791664]\n",
      "[37 72 74]\n",
      "[10.776267 65.54096  61.091988]\n",
      "[28 59 61]\n",
      "[ 6.2517743 60.64155   54.85779  ]\n",
      "[23 54 56]\n",
      "[-7.017828 48.944813 42.849144]\n",
      "[12 42 42]\n",
      "[-20.280773  35.55649   27.075052]\n",
      "[ 0 30 23]\n",
      "[-5.83958   32.28864    3.7950845]\n",
      "[ 0 29  9]\n",
      "[-8.152477   29.338678   -0.43764532]\n",
      "[ 0 27  0]\n",
      "[-12.845196   26.679218   -1.2876749]\n",
      "[ 0 23  0]\n",
      "[-9.629094   28.6029     -0.51680267]\n",
      "[ 0 26  0]\n",
      "[-3.7292795 33.237595   3.5652423]\n",
      "[ 0 33  6]\n",
      "[ 1.0580837 38.589134  10.411988 ]\n",
      "[ 1 40 13]\n",
      "[ 6.5870833 43.46278   15.415606 ]\n",
      "[ 6 45 16]\n",
      "[ 7.692885 44.437508 16.41632 ]\n",
      "[ 7 46 17]\n",
      "[21.704102 55.656338 26.581846]\n",
      "[19 58 29]\n",
      "[22.809902 56.63107  27.582582]\n",
      "[20 59 30]\n",
      "[26.12729  59.555252 30.584757]\n",
      "[23 62 31]\n",
      "[31.656284 64.428894 35.58836 ]\n",
      "[28 67 36]\n",
      "[39.396893 71.252    42.593403]\n",
      "[35 74 43]\n",
      "[46.03169  77.10037  48.597767]\n",
      "[41 80 49]\n",
      "[55.51841  83.41979  52.529095]\n",
      "[47 86 55]\n",
      "[59.941616 87.31871  56.531982]\n",
      "[50 91 59]\n",
      "[59.672104 88.55815  59.68485 ]\n",
      "[51 92 58]\n",
      "[63.731106 91.00443  60.843903]\n",
      "[52 96 61]\n",
      "[68.1543  94.90334 64.84679]\n",
      "[ 56 100  64]\n",
      "[72.47622  97.801765 66.61837 ]\n",
      "[ 59 104  65]\n",
      "[73.21784 97.32386 64.77523]\n",
      "[ 58 104  65]\n",
      "[71.909454 94.34812  59.311897]\n",
      "[ 55 102  58]\n",
      "[70.07531  90.46813  52.623474]\n",
      "[50 99 54]\n",
      "[67.762436 87.51818  48.390724]\n",
      "[47 97 48]\n",
      "[61.032993 78.97773  36.389668]\n",
      "[37 90 38]\n",
      "[65.72569  81.63719  37.239704]\n",
      "[40 93 37]\n",
      "[73.84375  86.52975  39.557762]\n",
      "[45 99 41]\n",
      "[79.64228  90.16393  41.408497]\n",
      "[ 49 103  41]\n",
      "[81.01758 89.89921 39.25634]\n",
      "[ 48 104  41]\n",
      "[76.863914 84.76085  32.1006  ]\n",
      "[43 99 34]\n",
      "[71.33491  79.8872   27.096992]\n",
      "[38 95 27]\n",
      "[66.911736 75.98829  23.094105]\n",
      "[34 90 25]\n",
      "[57.883816 73.81358  28.003326]\n",
      "[29 87 26]\n",
      "[52.35482  68.93994  22.999725]\n",
      "[26 81 23]\n",
      "[42.503925 61.167885 16.224506]\n",
      "[19 72 18]\n",
      "[29.801071 52.92478  11.52232 ]\n",
      "[13 61  9]\n",
      "[19.10726   44.630135   4.3589287]\n",
      "[ 9 51  5]\n",
      "[13.207453   39.995445    0.27689874]\n",
      "[ 7 44  0]\n",
      "[ 8.514735   37.335983   -0.57313085]\n",
      "[10 38  0]\n",
      "[ 6.4044347  36.387028   -0.34328878]\n",
      "[13 36  0]\n",
      "[ 5.5615034  35.86442    -0.73144555]\n",
      "[16 33  0]\n",
      "[17.1652    41.441227  -0.7953733]\n",
      "[29 38  0]\n",
      "[35.309013  50.174305  -0.8517015]\n",
      "[44 48  0]\n",
      "[51.605396   58.41056    -0.06559968]\n",
      "[58 57  0]\n",
      "[64.31488    64.962074    0.87118685]\n",
      "[70 65  1]\n",
      "[80.34175  74.43779   4.810147]\n",
      "[82 75  5]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m new_pixels \u001b[39m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(pixels)):\n\u001b[0;32m---> 13\u001b[0m     predicted_rgb \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(pixels[i:i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m/\u001b[39;49m\u001b[39m255.0\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     14\u001b[0m     new_pixels\u001b[39m.\u001b[39mappend(predicted_rgb[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m255.0\u001b[39m)\n\u001b[1;32m     15\u001b[0m     \u001b[39mprint\u001b[39m(predicted_rgb[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m255.0\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:2521\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2512\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m   2513\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2514\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2515\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2518\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   2519\u001b[0m         )\n\u001b[0;32m-> 2521\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[1;32m   2522\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   2523\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2524\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[1;32m   2525\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2526\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   2527\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2528\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2529\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2530\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2531\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[1;32m   2532\u001b[0m )\n\u001b[1;32m   2534\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2535\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1678\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1677\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1678\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1285\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1282\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[1;32m   1284\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1285\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   1286\u001b[0m     x,\n\u001b[1;32m   1287\u001b[0m     y,\n\u001b[1;32m   1288\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1289\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1290\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[1;32m   1291\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1292\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1293\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1294\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1295\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1296\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[1;32m   1297\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1298\u001b[0m     pss_evaluation_shards\u001b[39m=\u001b[39;49mpss_evaluation_shards,\n\u001b[1;32m   1299\u001b[0m )\n\u001b[1;32m   1301\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[1;32m   1303\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:353\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         flat_dataset \u001b[39m=\u001b[39m flat_dataset\u001b[39m.\u001b[39mshuffle(\u001b[39m1024\u001b[39m)\u001b[39m.\u001b[39mrepeat(epochs)\n\u001b[1;32m    351\u001b[0m     \u001b[39mreturn\u001b[39;00m flat_dataset\n\u001b[0;32m--> 353\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mflat_map(slice_batch_indices)\n\u001b[1;32m    355\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[1;32m    357\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2323\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[0;34m(self, map_func, name)\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> flat_map_op ->\u001b[39;00m\n\u001b[1;32m   2320\u001b[0m \u001b[39m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2321\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2322\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m flat_map_op\n\u001b[0;32m-> 2323\u001b[0m \u001b[39mreturn\u001b[39;00m flat_map_op\u001b[39m.\u001b[39;49m_flat_map(\u001b[39mself\u001b[39;49m, map_func, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/flat_map_op.py:24\u001b[0m, in \u001b[0;36m_flat_map\u001b[0;34m(input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_flat_map\u001b[39m(input_dataset, map_func, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m   \u001b[39mreturn\u001b[39;00m _FlatMapDataset(input_dataset, map_func, name)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/flat_map_op.py:33\u001b[0m, in \u001b[0;36m_FlatMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, input_dataset, map_func, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[0;32m---> 33\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[1;32m     34\u001b[0m       map_func, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(), dataset\u001b[39m=\u001b[39;49minput_dataset)\n\u001b[1;32m     35\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure, dataset_ops\u001b[39m.\u001b[39mDatasetSpec):\n\u001b[1;32m     36\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     37\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdataset_ops\u001b[39m.\u001b[39mget_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure)\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:272\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    266\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    270\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 272\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[1;32m    273\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1189\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1188\u001b[0m   \u001b[39m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m   concrete \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1190\u001b[0m   concrete\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1169\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m     initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m-> 1169\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwargs, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m   1170\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m   1173\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m   \u001b[39m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:694\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[39m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 694\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn    \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    695\u001b[0m     \u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(\n\u001b[1;32m    696\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    699\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:176\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 176\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[1;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    169\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:398\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m args \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39margs\n\u001b[1;32m    396\u001b[0m kwargs \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39mkwargs\n\u001b[0;32m--> 398\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(\n\u001b[1;32m    399\u001b[0m     args, kwargs, func_graph)\n\u001b[1;32m    401\u001b[0m \u001b[39m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:305\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m   arg_names \u001b[39m=\u001b[39m base_arg_names\n\u001b[1;32m    304\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 305\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    306\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m    307\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m    308\u001b[0m         args,\n\u001b[1;32m    309\u001b[0m         kwargs,\n\u001b[1;32m    310\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    311\u001b[0m         func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[1;32m    312\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m    313\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value,\n\u001b[1;32m    314\u001b[0m         create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m    316\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m    317\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    322\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1055\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1052\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m   1054\u001b[0m _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1055\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1057\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:597\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    594\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 597\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    598\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:238\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    239\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    240\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:168\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    167\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 168\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[1;32m    169\u001b[0m ret \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:334\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__.<locals>.slice_batch_indices\u001b[0;34m(indices)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \n\u001b[1;32m    319\u001b[0m \u001b[39mThis step can be accomplished in several ways. The most natural is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39m  A Dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    333\u001b[0m num_in_full_batch \u001b[39m=\u001b[39m num_full_batches \u001b[39m*\u001b[39m batch_size\n\u001b[0;32m--> 334\u001b[0m first_k_indices \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mslice(indices, [\u001b[39m0\u001b[39;49m], [num_in_full_batch])\n\u001b[1;32m    335\u001b[0m first_k_indices \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m    336\u001b[0m     first_k_indices, [num_full_batches, batch_size]\n\u001b[1;32m    337\u001b[0m )\n\u001b[1;32m    339\u001b[0m flat_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices(first_k_indices)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:1185\u001b[0m, in \u001b[0;36mslice\u001b[0;34m(input_, begin, size, name)\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mslice\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1134\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m   1135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mslice\u001b[39m(input_, begin, size, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1136\u001b[0m   \u001b[39m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Extracts a slice from a tensor.\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \n\u001b[1;32m   1139\u001b[0m \u001b[39m  See also `tf.strided_slice`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[39m    A `Tensor` the same type as `input_`.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1185\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_array_ops\u001b[39m.\u001b[39;49m_slice(input_, begin, size, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py:9614\u001b[0m, in \u001b[0;36m_slice\u001b[0;34m(input, begin, size, name)\u001b[0m\n\u001b[1;32m   9612\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m   9613\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m-> 9614\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[1;32m   9615\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mSlice\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m, begin\u001b[39m=\u001b[39;49mbegin, size\u001b[39m=\u001b[39;49msize, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   9616\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[1;32m   9617\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py:777\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[39mwith\u001b[39;00m g\u001b[39m.\u001b[39mas_default(), ops\u001b[39m.\u001b[39mname_scope(name) \u001b[39mas\u001b[39;00m scope:\n\u001b[1;32m    776\u001b[0m   \u001b[39mif\u001b[39;00m fallback:\n\u001b[0;32m--> 777\u001b[0m     _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[1;32m    778\u001b[0m                            keywords, default_type_attr_map, attrs, inputs,\n\u001b[1;32m    779\u001b[0m                            input_types)\n\u001b[1;32m    780\u001b[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[1;32m    781\u001b[0m                            default_type_attr_map, attrs)\n\u001b[1;32m    782\u001b[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py:550\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[1;32m    544\u001b[0m       values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    545\u001b[0m           values,\n\u001b[1;32m    546\u001b[0m           name\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mname,\n\u001b[1;32m    547\u001b[0m           as_ref\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mis_ref,\n\u001b[1;32m    548\u001b[0m           preferred_dtype\u001b[39m=\u001b[39mdefault_dtype)\n\u001b[1;32m    549\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(\n\u001b[1;32m    551\u001b[0m         values,\n\u001b[1;32m    552\u001b[0m         name\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    553\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    554\u001b[0m         as_ref\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mis_ref,\n\u001b[1;32m    555\u001b[0m         preferred_dtype\u001b[39m=\u001b[39;49mdefault_dtype)\n\u001b[1;32m    556\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    557\u001b[0m   \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1443\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[39m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m   1442\u001b[0m preferred_dtype \u001b[39m=\u001b[39m preferred_dtype \u001b[39mor\u001b[39;00m dtype_hint\n\u001b[0;32m-> 1443\u001b[0m \u001b[39mreturn\u001b[39;00m tensor_conversion_registry\u001b[39m.\u001b[39;49mconvert(\n\u001b[1;32m   1444\u001b[0m     value, dtype, name, as_ref, preferred_dtype, accepted_result_types\n\u001b[1;32m   1445\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:324\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    322\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    323\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[0;32m--> 324\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:263\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    168\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    264\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:277\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    275\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 277\u001b[0m const_tensor \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49m_create_graph_constant(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    278\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    279\u001b[0m )\n\u001b[1;32m    280\u001b[0m \u001b[39mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1013\u001b[0m, in \u001b[0;36m_create_graph_constant\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m   1011\u001b[0m dtype_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mtensor_value\u001b[39m.\u001b[39mtensor\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m   1012\u001b[0m attrs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m: tensor_value, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m: dtype_value}\n\u001b[0;32m-> 1013\u001b[0m const_tensor \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m   1014\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mConst\u001b[39;49m\u001b[39m\"\u001b[39;49m, [], [dtype_value\u001b[39m.\u001b[39;49mtype], attrs\u001b[39m=\u001b[39;49mattrs, name\u001b[39m=\u001b[39;49mname)\u001b[39m.\u001b[39moutputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1016\u001b[0m \u001b[39mif\u001b[39;00m op_callbacks\u001b[39m.\u001b[39mshould_invoke_op_callbacks():\n\u001b[1;32m   1017\u001b[0m   \u001b[39m# TODO(b/147670703): Once the special-op creation code paths\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m   \u001b[39m# are unified. Remove this `if` block.\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m   callback_outputs \u001b[39m=\u001b[39m op_callbacks\u001b[39m.\u001b[39minvoke_op_callbacks(\n\u001b[1;32m   1020\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtuple\u001b[39m(), attrs, (const_tensor,), op_name\u001b[39m=\u001b[39mname, graph\u001b[39m=\u001b[39mg)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    668\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[1;32m    669\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[0;32m--> 670\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    671\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[1;32m    672\u001b[0m     compute_device)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:3381\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3378\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   3379\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   3380\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 3381\u001b[0m   ret \u001b[39m=\u001b[39m Operation\u001b[39m.\u001b[39;49mfrom_node_def(\n\u001b[1;32m   3382\u001b[0m       node_def,\n\u001b[1;32m   3383\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   3384\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m   3385\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[1;32m   3386\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[1;32m   3387\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m   3388\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[1;32m   3389\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def,\n\u001b[1;32m   3390\u001b[0m   )\n\u001b[1;32m   3391\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[1;32m   3392\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1889\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1886\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[1;32m   1888\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[0;32m-> 1889\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m   1890\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Operation(c_op, GraphTensor)\n\u001b[1;32m   1891\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init(g)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1718\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1715\u001b[0m   op_def \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39mop_def_for_type(node_def\u001b[39m.\u001b[39mop)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m \u001b[39m# TODO(skyewm): op_def_library.apply_op() flattens the incoming inputs.\u001b[39;00m\n\u001b[1;32m   1717\u001b[0m \u001b[39m# Refactor so we don't have to do this here.\u001b[39;00m\n\u001b[0;32m-> 1718\u001b[0m inputs \u001b[39m=\u001b[39m _reconstruct_sequence_inputs(op_def, inputs, node_def\u001b[39m.\u001b[39;49mattr)\n\u001b[1;32m   1719\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39m_c_graph\u001b[39m.\u001b[39mget() \u001b[39mas\u001b[39;00m c_graph:\n",
      "File \u001b[0;32m~/Downloads/EAAI 24 Research Paper/Code/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:6692\u001b[0m, in \u001b[0;36m_reconstruct_sequence_inputs\u001b[0;34m(op_def, inputs, attrs)\u001b[0m\n\u001b[1;32m   6686\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   6687\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot add scope exit callbacks when not building a function.  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   6688\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDefault graph: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(default_graph))\n\u001b[1;32m   6689\u001b[0m   default_graph\u001b[39m.\u001b[39m_add_scope_exit_callback(fn)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 6692\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_reconstruct_sequence_inputs\u001b[39m(op_def, inputs, attrs):\n\u001b[1;32m   6693\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Regroups a flat list of input tensors into scalar and sequence inputs.\u001b[39;00m\n\u001b[1;32m   6694\u001b[0m \n\u001b[1;32m   6695\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6703\u001b[0m \u001b[39m    `Tensor`s (corresponding to sequence inputs).\u001b[39;00m\n\u001b[1;32m   6704\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m   6705\u001b[0m   grouped_inputs \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = 'test6_images/test6.jpeg_1_1.0.png'\n",
    "path2 = 'test6_images/test6.jpeg'\n",
    "im = Image.open(path)\n",
    "im2 = Image.open(path2)\n",
    "height, width = im.size\n",
    "pixels = list(im.getdata())\n",
    "pixels2 = list(im2.getdata())\n",
    "pixels = np.array(pixels)\n",
    "pixels2 = np.array(pixels2)\n",
    "\n",
    "new_pixels = []\n",
    "for i in range(len(pixels)):\n",
    "    predicted_rgb = model.predict(pixels[i:i+1]/255.0, verbose=0)\n",
    "    new_pixels.append(predicted_rgb[0]*255.0)\n",
    "    print(predicted_rgb[0]*255.0)\n",
    "    print(pixels2[i])\n",
    "\n",
    "new_pixels = np.array(new_pixels)\n",
    "new_pixels2 = np.ravel(new_pixels)\n",
    "new_image = Image.fromarray(new_pixels2.reshape(width, height, 3).astype('uint8'))\n",
    "new_image.save(f'fixed.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
